
model parameters = 82M
train dataset tokens = 315M
train FLOPs = 4.49e+15



























































































































































 93%|███████████████████████████████████▌  | 1869/2000 [05:13<00:21,  5.96it/s, train loss=7.09, TFLOPS=13.6]
Traceback (most recent call last):
  File "/home/ubuntu/LLM/HW3/llms-class-hw-3-main/src/train/train.py", line 313, in <module>
    main()
  File "/home/ubuntu/LLM/HW3/llms-class-hw-3-main/src/train/train.py", line 288, in main
    train(
  File "/home/ubuntu/LLM/HW3/llms-class-hw-3-main/src/train/train.py", line 174, in train
    loss.backward()
  File "/home/ubuntu/miniconda3/envs/HW3/lib/python3.10/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/home/ubuntu/miniconda3/envs/HW3/lib/python3.10/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt